# ğŸš€ Kafka Saldo Demo - TÃ³pico Compactado + API REST

Este projeto demonstra o uso de **Apache Kafka com tÃ³pico compactado** como fonte de estado para um sistema de consulta de saldos. Utilizamos Python com `confluent-kafka` e Flask para criar um serviÃ§o REST que reconstrÃ³i e mantÃ©m o estado em memÃ³ria.

## ğŸ“‹ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     produz      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Producer â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Kafka (compacted)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  topic: contas   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â”‚ consome
                                       â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ Consumer Service â”‚
                              â”‚  (Flask + API)   â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ GET /saldo/{id}  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Estrutura do Projeto

```
kafka-saldo-demo/
â”œâ”€â”€ docker-compose.yml      # Kafka + Zookeeper
â”œâ”€â”€ create_topic.sh         # Script para criar tÃ³pico compactado
â”œâ”€â”€ start.sh               # â­ Script para iniciar todo o sistema
â”œâ”€â”€ stop.sh                # â­ Script para parar todo o sistema
â”œâ”€â”€ .env                    # ConfiguraÃ§Ãµes
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ producer.py            # Produz atualizaÃ§Ãµes de saldo
â”œâ”€â”€ producer_interactive.py # â­ Producer interativo (CLI)
â”œâ”€â”€ consumer_service.py    # ReconstrÃ³i estado e expÃµe API
â”œâ”€â”€ README.md              # Esta documentaÃ§Ã£o
â””â”€â”€ .vscode/
    â”œâ”€â”€ tasks.json         # Tasks do VS Code
    â””â”€â”€ launch.json        # ConfiguraÃ§Ãµes de debug
```

## ğŸš¦ Como Rodar

### ğŸ¯ InÃ­cio RÃ¡pido (Recomendado)

Use o script automatizado que faz tudo pra vocÃª:

```bash
./start.sh
```

Isso irÃ¡:
- âœ… Iniciar Kafka e Zookeeper
- âœ… Criar o tÃ³pico compactado
- âœ… Criar virtualenv (se necessÃ¡rio)
- âœ… Instalar dependÃªncias
- âœ… Enviar mensagens de teste
- âœ… Iniciar a API REST

Para parar tudo:

```bash
./stop.sh
```

### ğŸ“š Passo a Passo Manual

Se preferir fazer manualmente:

### 1ï¸âƒ£ PrÃ©-requisitos

- Docker e Docker Compose instalados
- Python 3.8+ instalado
- VS Code (opcional, mas recomendado)

### 2ï¸âƒ£ Iniciar Kafka

```bash
docker-compose up -d
```

Verificar containers:
```bash
docker ps
```

### 3ï¸âƒ£ Criar TÃ³pico Compactado

Tornar o script executÃ¡vel:
```bash
chmod +x create_topic.sh
```

Executar:
```bash
./create_topic.sh
```

**Alternativa manual:**
```bash
docker-compose exec kafka bash
kafka-topics --create --topic contas --bootstrap-server localhost:9092 \
  --partitions 1 --replication-factor 1 --config cleanup.policy=compact
exit
```

### 4ï¸âƒ£ Configurar Python

Criar virtualenv e instalar dependÃªncias:

```bash
python -m venv .venv
source .venv/bin/activate  # No macOS/Linux
pip install -r requirements.txt
```

### 5ï¸âƒ£ Iniciar Consumer Service (API)

```bash
python consumer_service.py
```

Isso irÃ¡:
- âœ… Reconstruir estado a partir do tÃ³pico
- âœ… Iniciar consumer em background
- âœ… Expor API em `http://localhost:5000`

### 6ï¸âƒ£ Produzir Mensagens

**OpÃ§Ã£o 1: Producer AutomÃ¡tico**

```bash
python producer.py
```

**OpÃ§Ã£o 2: Producer Interativo** â­

```bash
python producer_interactive.py
# Digite o ID do cliente e o saldo quando solicitado
```

### 7ï¸âƒ£ Testar API

```bash
# Via curl
curl http://localhost:5000/saldo/1
curl http://localhost:5000/saldo/2

# Ou abra no navegador:
# http://localhost:5000/saldo/1
```

**Resposta esperada:**
```json
{
  "cliente_id": "1",
  "saldo": 150.0,
  "timestamp": "2025-10-14T10:30:45"
}
```

## ğŸ¯ Endpoints da API

### GET /saldo/{cliente_id}

Retorna o saldo atual de um cliente.

**Sucesso (200):**
```json
{
  "cliente_id": "1",
  "saldo": 150.0,
  "timestamp": "2025-10-14T10:30:45"
}
```

**NÃ£o encontrado (404):**
```json
{
  "error": "cliente nÃ£o encontrado"
}
```

## ğŸ› ï¸ Usando VS Code

### Tasks DisponÃ­veis

Pressione `Cmd+Shift+P` (macOS) ou `Ctrl+Shift+P` (Windows/Linux) e digite "Run Task":

- **Docker Compose Up** - Inicia Kafka
- **Create Topic** - Cria tÃ³pico compactado
- **Run Consumer Service** - Inicia API
- **Run Producer** - Envia mensagens

### Debug

Use F5 para iniciar debug do `consumer_service.py` ou `producer.py`

## âš™ï¸ ConfiguraÃ§Ã£o

Arquivo `.env`:

```env
BOOTSTRAP_SERVERS=localhost:9092
TOPIC=contas
GROUP=consulta-saldo
```

## ğŸ“Š Como Funciona

### TÃ³pico Compactado

O Kafka mantÃ©m **apenas a Ãºltima mensagem** de cada chave (cliente_id). Isso permite:

- âœ… Estado compacto (nÃ£o cresce indefinidamente)
- âœ… ReconstruÃ§Ã£o rÃ¡pida do estado
- âœ… HistÃ³rico auditÃ¡vel (antes da compactaÃ§Ã£o)

### ReconstruÃ§Ã£o de Estado

1. **Startup**: Consumer lÃª todo o tÃ³pico desde o inÃ­cio
2. **ConstrÃ³i mapa** em memÃ³ria: `cliente_id â†’ Ãºltima_mensagem`
3. **Consumer streaming** atualiza o mapa com novas mensagens
4. **API** consulta o mapa em memÃ³ria

## âš ï¸ LimitaÃ§Ãµes e Riscos

### ğŸ”´ Estado em MemÃ³ria

- Restart do serviÃ§o = perda temporÃ¡ria de estado
- ReconstruÃ§Ã£o pode demorar em tÃ³picos grandes
- Sem persistÃªncia local (considerar RocksDB/Kafka Streams)

### ğŸ”´ Sem TransaÃ§Ãµes

- ConcorrÃªncia pode causar race conditions
- MÃºltiplos producers = possÃ­veis inconsistÃªncias
- NÃ£o hÃ¡ isolamento ACID

### ğŸ”´ CompactaÃ§Ã£o Eventual

- Mensagens antigas permanecem atÃ© compactaÃ§Ã£o
- Processo nÃ£o Ã© instantÃ¢neo
- Log pode crescer temporariamente

### ğŸ”´ ConsistÃªncia

- NÃ£o garante strong consistency
- Eventual consistency apenas
- NÃ£o substitui banco transacional

## ğŸš€ Melhorias para ProduÃ§Ã£o

### 1. PersistÃªncia

```python
# Usar RocksDB ou Kafka Streams State Store
# Evita reconstruÃ§Ã£o completa apÃ³s restart
```

### 2. MÃºltiplas PartiÃ§Ãµes

```bash
kafka-topics --create --topic contas \
  --partitions 3 \  # mÃºltiplas partiÃ§Ãµes
  --replication-factor 3
```

### 3. SeguranÃ§a

```python
# TLS/SSL + SASL
conf = {
    'security.protocol': 'SASL_SSL',
    'sasl.mechanism': 'PLAIN',
    'sasl.username': 'user',
    'sasl.password': 'pass'
}
```

### 4. Monitoramento

```python
# Adicionar mÃ©tricas Prometheus
# Expor health checks
# Logging estruturado
```

### 5. Kafka Streams / ksqlDB

Considere usar ferramentas nativas do Kafka para materializaÃ§Ã£o:

```sql
-- ksqlDB
CREATE TABLE saldos AS
  SELECT cliente_id, LATEST_BY_OFFSET(saldo) as saldo
  FROM contas_stream
  GROUP BY cliente_id;
```

## ğŸ§ª Comandos Ãšteis

### Verificar TÃ³picos

```bash
docker-compose exec kafka kafka-topics --list --bootstrap-server localhost:9092
```

### Descrever TÃ³pico

```bash
docker-compose exec kafka kafka-topics --describe \
  --topic contas --bootstrap-server localhost:9092
```

### Consumir Manualmente

```bash
docker-compose exec kafka kafka-console-consumer \
  --topic contas --from-beginning \
  --bootstrap-server localhost:9092 \
  --property print.key=true
```

### Produzir Manualmente

```bash
docker-compose exec kafka kafka-console-producer \
  --topic contas --bootstrap-server localhost:9092 \
  --property "parse.key=true" \
  --property "key.separator=:"
# Digite: 3:{"cliente_id":"3","saldo":300.0,"timestamp":"2025-10-14T10:00:00"}
```

### Limpar Ambiente

```bash
docker-compose down -v  # Remove containers e volumes
```

## ğŸ“š Recursos Adicionais

- [Confluent Kafka Python](https://docs.confluent.io/kafka-clients/python/current/overview.html)
- [Kafka Log Compaction](https://kafka.apache.org/documentation/#compaction)
- [Kafka Streams](https://kafka.apache.org/documentation/streams/)
- [ksqlDB](https://ksqldb.io/)

## ğŸ“ LicenÃ§a

Projeto de demonstraÃ§Ã£o - use livremente para aprendizado.

---

**Dica Final:** Este projeto Ã© ideal para **aprendizado e prototipagem**. Para produÃ§Ã£o, considere Kafka Streams ou ksqlDB para materializaÃ§Ã£o robusta de estado! ğŸ¯
