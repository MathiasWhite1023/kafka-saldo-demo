# ğŸ Kafka Saldo Demo - VersÃ£o Python

Sistema de consulta de saldos bancÃ¡rios usando **Apache Kafka com tÃ³pico compactado** como fonte Ãºnica de verdade.

> **ğŸ’¡ Esta Ã© a implementaÃ§Ã£o em Python com Flask.**  
> Para a versÃ£o Java/Spring Boot, veja a branch [`java-version`](../../tree/java-version)

---

## ğŸ“š Ãndice

- [Por Que Kafka?](#-por-que-kafka)
- [Como Funciona](#-como-funciona)
- [Tecnologias Usadas](#-tecnologias-usadas)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Como Usar](#-como-usar)
- [Testando](#-testando)
- [Entendendo o CÃ³digo](#-entendendo-o-cÃ³digo)

---

## ğŸ¯ Por Que Kafka?

### Problema: Como manter saldos bancÃ¡rios sempre atualizados?

**Abordagem tradicional (banco de dados):**
```
Cliente 1: R$ 100,00  â† valor atual
Cliente 2: R$ 50,00   â† valor atual
```
âŒ NÃ£o hÃ¡ histÃ³rico de mudanÃ§as  
âŒ Se o banco cair, perdemos o estado  
âŒ DifÃ­cil de replicar para mÃºltiplos serviÃ§os  

**Abordagem com Kafka (Event Sourcing):**
```
TÃ³pico 'contas' (compactado):
  cliente_1 â†’ {"saldo": 200.0}  â† substituÃ­do
  cliente_1 â†’ {"saldo": 150.0}  â† Ãºltima versÃ£o (mantida)
  cliente_2 â†’ {"saldo": 50.0}   â† Ãºltima versÃ£o (mantida)
```
âœ… Log de eventos como fonte Ãºnica de verdade  
âœ… CompactaÃ§Ã£o mantÃ©m apenas Ãºltimo estado  
âœ… Qualquer serviÃ§o pode reconstruir o estado completo  
âœ… Alta disponibilidade e tolerÃ¢ncia a falhas  

### ğŸ”‘ Conceito Principal: TÃ³pico Compactado

Kafka com **log compaction** garante:
1. **Apenas a Ãºltima mensagem** por chave (cliente_id) Ã© mantida
2. **ReconstruÃ§Ã£o completa** do estado lendo o tÃ³pico do inÃ­cio
3. **AtualizaÃ§Ãµes em tempo real** conforme novas mensagens chegam

**Exemplo:**
```python
# Envio 3 mensagens para o mesmo cliente:
producer.send(key="1", value={"saldo": 100.0})  # SerÃ¡ removida
producer.send(key="1", value={"saldo": 200.0})  # SerÃ¡ removida
producer.send(key="1", value={"saldo": 150.0})  # âœ… Esta fica!

# Ao consumir o tÃ³pico, sÃ³ veremos a Ãºltima:
consumer.poll() # â†’ {"cliente_id": "1", "saldo": 150.0}
```

---

## ğŸ—ï¸ Como Funciona

### Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producer       â”‚  1) Envia atualizaÃ§Ãµes de saldo
â”‚  (Python CLI)   â”‚     com cliente_id como chave
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kafka Topic: "contas" (compacted)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ key="1" â†’ {"saldo": 150.0}      â”‚   â”‚  2) Kafka mantÃ©m
â”‚  â”‚ key="2" â†’ {"saldo": 50.0}       â”‚   â”‚     apenas Ãºltima
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     mensagem/chave
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Consumer Service (Flask)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Startup:                      â”‚  â”‚  3) ReconstrÃ³i
â”‚  â”‚     - LÃª tÃ³pico do inÃ­cio         â”‚  â”‚     estado em
â”‚  â”‚     - ReconstrÃ³i estado em dict   â”‚  â”‚     memÃ³ria
â”‚  â”‚                                   â”‚  â”‚
â”‚  â”‚  2. Runtime:                      â”‚  â”‚  4) Atualiza
â”‚  â”‚     - Escuta novas mensagens      â”‚  â”‚     estado em
â”‚  â”‚     - Atualiza dict em memÃ³ria    â”‚  â”‚     tempo real
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                          â”‚
â”‚  API REST (Flask):                       â”‚
â”‚    GET /saldo/{id}  â†’ Consulta saldo    â”‚  5) ExpÃµe API
â”‚    GET /saldos      â†’ Lista todos       â”‚     para consulta
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

**1. Producer envia atualizaÃ§Ã£o:**
```python
# producer.py ou producer_interactive.py
producer.send(
    topic='contas',
    key='1',                          # cliente_id
    value='{"cliente_id":"1","saldo":150.0,"timestamp":"..."}'
)
```

**2. Kafka armazena e compacta:**
- Mensagens com mesma chave (cliente_id) sÃ£o compactadas
- Apenas a mais recente Ã© mantida

**3. Consumer reconstrÃ³i estado:**
```python
# consumer_service.py - Startup
estado = {}
for msg in consumer.poll_from_beginning():
    estado[msg.key] = msg.value  # Dict em memÃ³ria
# estado = {"1": {"saldo": 150.0}, "2": {"saldo": 50.0}}
```

**4. API responde consultas:**
```python
# consumer_service.py - API
@app.route("/saldo/<cliente_id>")
def get_saldo(cliente_id):
    return estado.get(cliente_id)  # Busca em memÃ³ria
```

---

## ğŸ’» Tecnologias Usadas

### Core
- **Python 3.8+** - Linguagem principal
- **Apache Kafka** - Message broker com tÃ³pico compactado
- **Zookeeper** - CoordenaÃ§Ã£o do cluster Kafka

### Python Libraries
- **Flask** - Web framework para API REST
- **Flask-CORS** - Habilitar CORS na API
- **confluent-kafka** - Cliente Kafka para Python
- **python-dotenv** - Gerenciar variÃ¡veis de ambiente

### DevOps
- **Docker Compose** - OrquestraÃ§Ã£o Kafka + Zookeeper
- **Shell Scripts** - AutomaÃ§Ã£o (start.sh, stop.sh)

### Frontend (Bonus)
- **HTML/CSS/JavaScript** - Dashboard web interativo

---

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- **Docker** e **Docker Compose** instalados
- **Python 3.8+** instalado
- **Git** (para clonar o repositÃ³rio)

### Passo 1: Clonar o RepositÃ³rio

```bash
git clone https://github.com/MathiasWhite1023/kafka-saldo-demo.git
cd kafka-saldo-demo
git checkout python-version
```

### Passo 2: Iniciar Kafka

```bash
# Inicia Kafka e Zookeeper em containers Docker
docker-compose up -d

# Aguarda Kafka estar pronto (5-10 segundos)
sleep 10

# Cria o tÃ³pico compactado
./create_topic.sh
```

**O que acontece:**
- Kafka sobe na porta `9092`
- Zookeeper sobe na porta `2181`
- TÃ³pico `contas` Ã© criado com `cleanup.policy=compact`

### Passo 3: Instalar DependÃªncias Python

```bash
# Criar ambiente virtual
python3 -m venv .venv

# Ativar ambiente virtual
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

**DependÃªncias instaladas:**
```
Flask==2.3.2
Flask-CORS==4.0.0
confluent-kafka==2.1.1
python-dotenv==1.0.0
```

---

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Script Automatizado (Recomendado)

```bash
./start.sh
```

Este script faz tudo automaticamente:
1. âœ… Inicia Kafka e Zookeeper
2. âœ… Cria o tÃ³pico compactado
3. âœ… Cria virtualenv e instala dependÃªncias
4. âœ… Envia mensagens de teste
5. âœ… Inicia a API REST

### OpÃ§Ã£o 2: Passo a Passo Manual

#### 1. Enviar Mensagens de Teste

```bash
# Ativar virtualenv
source .venv/bin/activate

# Enviar mensagens via producer batch
python producer.py
```

**SaÃ­da esperada:**
```
Produzido -> key=1 value={'cliente_id': '1', 'saldo': 200.0, ...}
Produzido -> key=2 value={'cliente_id': '2', 'saldo': 50.0, ...}
Produzido -> key=1 value={'cliente_id': '1', 'saldo': 150.0, ...}
Mensagens enviadas.
```

#### 2. Iniciar Consumer Service (API)

```bash
python consumer_service.py
```

**SaÃ­da esperada:**
```
Reconstruindo estado a partir do tÃ³pico...
ReconstruÃ§Ã£o finalizada. NÃºmero de chaves: 2
Consumer streaming iniciado, aguardando novas mensagens...
 * Running on http://127.0.0.1:5001
```

#### 3. Adicionar Novos Clientes (Opcional)

```bash
# Em outro terminal
source .venv/bin/activate
python producer_interactive.py
```

**Uso:**
```
Cliente ID: 3
Saldo: 500.00
âœ… Mensagem enviada!

Cliente ID: 4
Saldo: 1000.00
âœ… Mensagem enviada!
```

---

## ğŸ§ª Testando

### 1. Testar API via cURL

**Consultar saldo de um cliente:**
```bash
curl http://localhost:5001/saldo/1
```

**Resposta:**
```json
{
  "cliente_id": "1",
  "saldo": 150.0,
  "timestamp": "2025-10-14T15:20:57"
}
```

**Listar todos os saldos:**
```bash
curl http://localhost:5001/saldos
```

**Resposta:**
```json
{
  "total": 2,
  "clientes": [
    {"cliente_id": "1", "saldo": 150.0, "timestamp": "2025-10-14T15:20:57"},
    {"cliente_id": "2", "saldo": 50.0, "timestamp": "2025-10-14T15:20:56"}
  ]
}
```

### 2. Dashboard Web

**Iniciar servidor HTTP:**
```bash
python3 -m http.server 8080
```

**Acessar dashboard:**
- Simples: http://localhost:8080/dashboard.html
- Universal: http://localhost:8080/dashboard-universal.html

**Features do Dashboard:**
- ğŸ” Busca de saldo por cliente ID
- ğŸ“Š VisualizaÃ§Ã£o bonita dos dados
- âš¡ Status da API em tempo real
- ğŸ¨ Interface moderna e responsiva

### 3. Demonstrar CompactaÃ§Ã£o do Kafka

**Enviar mÃºltiplas atualizaÃ§Ãµes para o mesmo cliente:**
```bash
python producer_interactive.py

# Digite:
Cliente ID: 5
Saldo: 100.00

Cliente ID: 5
Saldo: 200.00

Cliente ID: 5
Saldo: 300.00
```

**Consultar saldo:**
```bash
curl http://localhost:5001/saldo/5
```

**Resultado:**
```json
{
  "cliente_id": "5",
  "saldo": 300.0,  # â† Apenas o Ãºltimo valor!
  "timestamp": "..."
}
```

**âœ¨ Isso prova que o Kafka estÃ¡ compactando:** apenas a Ãºltima mensagem por chave Ã© mantida!

### 4. Testar ReconstruÃ§Ã£o de Estado

**Parar o consumer:**
```bash
pkill -f consumer_service.py
```

**Reiniciar:**
```bash
python consumer_service.py
```

**Observar logs:**
```
Reconstruindo estado a partir do tÃ³pico...
ReconstruÃ§Ã£o finalizada. NÃºmero de chaves: 5  # â† Estado reconstruÃ­do!
```

**Consultar novamente:**
```bash
curl http://localhost:5001/saldo/5
# âœ… Dados ainda estÃ£o lÃ¡! Estado foi reconstruÃ­do do Kafka
```

---

## ğŸ” Entendendo o CÃ³digo

### 1. Producer (`producer_interactive.py`)

```python
from confluent_kafka import Producer
import json, os
from datetime import datetime

# ConfiguraÃ§Ã£o do producer
producer = Producer({'bootstrap.servers': 'localhost:9092'})

# FunÃ§Ã£o para enviar mensagem
def send_update(cliente_id, saldo):
    value = {
        "cliente_id": cliente_id,
        "saldo": saldo,
        "timestamp": datetime.now().isoformat()
    }
    
    # KEY = cliente_id (importante para compactaÃ§Ã£o!)
    producer.produce(
        topic='contas',
        key=str(cliente_id),           # Chave = ID do cliente
        value=json.dumps(value)        # Valor = JSON com saldo
    )
    producer.flush()  # Garante envio
```

**ğŸ”‘ Ponto-chave:** A `key` Ã© o cliente_id! Isso permite ao Kafka compactar mensagens do mesmo cliente.

### 2. Consumer Service (`consumer_service.py`)

**ReconstruÃ§Ã£o de Estado (Startup):**
```python
def rebuild_state():
    consumer = Consumer({
        'bootstrap.servers': 'localhost:9092',
        'group.id': 'consulta-saldo-rebuild',
        'auto.offset.reset': 'earliest'  # LÃª do inÃ­cio!
    })
    
    consumer.assign([TopicPartition('contas', 0, 0)])  # PartiÃ§Ã£o 0, offset 0
    
    estado = {}
    while True:
        msg = consumer.poll(1.0)
        if msg is None:
            break  # Fim do tÃ³pico
        
        key = msg.key().decode('utf-8')
        value = json.loads(msg.value().decode('utf-8'))
        estado[key] = value  # Ãšltima mensagem por key
    
    return estado  # Dict em memÃ³ria
```

**Streaming Consumer (Runtime):**
```python
def run_streaming_consumer():
    consumer = Consumer({
        'bootstrap.servers': 'localhost:9092',
        'group.id': 'consulta-saldo',
        'auto.offset.reset': 'latest'  # SÃ³ novas mensagens
    })
    
    consumer.subscribe(['contas'])
    
    while True:
        msg = consumer.poll(1.0)
        if msg is None:
            continue
        
        key = msg.key().decode('utf-8')
        value = json.loads(msg.value().decode('utf-8'))
        
        with estado_lock:
            estado[key] = value  # Atualiza estado em memÃ³ria
        
        print(f"Atualizado: {key} -> {value}")
```

**API REST (Flask):**
```python
from flask import Flask, jsonify
from flask_cors import CORS

app = Flask(__name__)
CORS(app)  # Permite chamadas do dashboard web

@app.route("/saldo/<cliente_id>")
def get_saldo(cliente_id):
    with estado_lock:
        data = estado.get(str(cliente_id))
    
    if data:
        return jsonify(data)
    else:
        return jsonify({"error": "cliente nÃ£o encontrado"}), 404

@app.route("/saldos")
def get_all():
    with estado_lock:
        all_data = [{"cliente_id": k, **v} for k, v in estado.items()]
    return jsonify({"total": len(all_data), "clientes": all_data})
```

### 3. Docker Compose (`docker-compose.yml`)

```yaml
version: '3'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_CLEANUP_POLICY: compact  # â† CompactaÃ§Ã£o!
```

### 4. CriaÃ§Ã£o do TÃ³pico (`create_topic.sh`)

```bash
docker exec kafka-saldo-demo-kafka-1 \
  kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --topic contas \
    --partitions 1 \
    --replication-factor 1 \
    --config cleanup.policy=compact \      # â† COMPACTAÃ‡ÃƒO!
    --config segment.ms=10000 \            # Compacta a cada 10s
    --config min.cleanable.dirty.ratio=0.01
```

**ConfiguraÃ§Ãµes importantes:**
- `cleanup.policy=compact` - Ativa compactaÃ§Ã£o
- `segment.ms=10000` - ForÃ§a compactaÃ§Ã£o frequente (10s)
- `min.cleanable.dirty.ratio=0.01` - Compacta agressivamente

---

## ğŸ“Š Estrutura do Projeto

```
kafka-saldo-demo/ (branch python-version)
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Esta documentaÃ§Ã£o
â”œâ”€â”€ ğŸ“„ TESTING.md                   # CenÃ¡rios de teste detalhados
â”œâ”€â”€ ğŸ“„ GUIA_COMPLETO.md            # Guia completo do sistema
â”œâ”€â”€ ğŸ“„ QUICK_START.md              # InÃ­cio rÃ¡pido
â”œâ”€â”€ ğŸ“„ STATUS.txt                  # Status do sistema
â”‚
â”œâ”€â”€ ğŸ CÃ“DIGO PYTHON
â”‚   â”œâ”€â”€ consumer_service.py        # Consumer + API REST
â”‚   â”œâ”€â”€ producer.py                # Producer batch (demo)
â”‚   â””â”€â”€ producer_interactive.py    # Producer interativo (CLI)
â”‚
â”œâ”€â”€ ğŸ³ INFRAESTRUTURA
â”‚   â”œâ”€â”€ docker-compose.yml         # Kafka + Zookeeper
â”‚   â”œâ”€â”€ create_topic.sh            # Cria tÃ³pico compactado
â”‚   â”œâ”€â”€ start.sh                   # Inicia tudo
â”‚   â””â”€â”€ stop.sh                    # Para tudo
â”‚
â”œâ”€â”€ ğŸ“¦ DEPENDÃŠNCIAS
â”‚   â”œâ”€â”€ requirements.txt           # Libs Python
â”‚   â””â”€â”€ .gitignore                 # Arquivos ignorados
â”‚
â””â”€â”€ ğŸŒ FRONTEND
    â”œâ”€â”€ dashboard.html             # Dashboard simples
    â””â”€â”€ dashboard-universal.html   # Dashboard avanÃ§ado
```

---

## ğŸ›‘ Parar o Sistema

```bash
./stop.sh
```

Ou manualmente:
```bash
# Parar consumer
pkill -f consumer_service.py

# Parar Kafka
docker-compose down
```

---

## ğŸ› Troubleshooting

### Erro: "Connection refused" ao conectar no Kafka

**Problema:** Kafka ainda nÃ£o estÃ¡ pronto.

**SoluÃ§Ã£o:**
```bash
# Aguardar Kafka inicializar
sleep 10

# Verificar se estÃ¡ rodando
docker ps | grep kafka
```

### Erro: "Port 5001 already in use"

**Problema:** Porta 5001 em uso (AirPlay no macOS).

**SoluÃ§Ã£o 1 - Desabilitar AirPlay:**
- System Settings â†’ General â†’ AirDrop & Handoff
- Desligar "AirPlay Receiver"

**SoluÃ§Ã£o 2 - Mudar porta no cÃ³digo:**
```python
# consumer_service.py (Ãºltima linha)
app.run(port=5002)  # Usar porta 5002
```

### Erro: "No messages in topic"

**Problema:** TÃ³pico vazio.

**SoluÃ§Ã£o:**
```bash
# Enviar mensagens de teste
python producer.py
```

### Consumer nÃ£o reconstrÃ³i estado

**Problema:** Consumer nÃ£o estÃ¡ lendo do inÃ­cio.

**SoluÃ§Ã£o:**
```python
# Verificar auto.offset.reset em consumer_service.py
'auto.offset.reset': 'earliest'  # â† Deve ser 'earliest'
```

---

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o

- [Apache Kafka Docs](https://kafka.apache.org/documentation/)
- [Confluent Kafka Python](https://docs.confluent.io/kafka-clients/python/current/overview.html)
- [Log Compaction](https://kafka.apache.org/documentation/#compaction)
- [Flask Quickstart](https://flask.palletsprojects.com/quickstart/)

### Conceitos AvanÃ§ados

- **Event Sourcing** - Estado derivado de eventos
- **CQRS** - SeparaÃ§Ã£o de leitura/escrita
- **Stateful Services** - ServiÃ§os com estado derivado de eventos
- **Log Compaction** - Manter apenas Ãºltimo estado por chave

---

## ğŸ¯ Casos de Uso Reais

Este padrÃ£o Ã© usado em:

1. **Banking/Fintech** - Saldos de contas, transaÃ§Ãµes
2. **E-commerce** - InventÃ¡rio de produtos, carrinhos
3. **Gaming** - Estado de jogadores, rankings
4. **IoT** - Ãšltimo estado de dispositivos
5. **Monitoring** - MÃ©tricas e status de sistemas

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas!

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/MinhaFeature`
3. Commit: `git commit -m 'Adiciona MinhaFeature'`
4. Push: `git push origin feature/MinhaFeature`
5. Abra um Pull Request

---

## ğŸ“ LicenÃ§a

Este projeto Ã© open source sob a licenÃ§a MIT.

---

## ğŸŒŸ Outras VersÃµes

- â˜• **VersÃ£o Java/Spring Boot:** [java-version branch](../../tree/java-version)
- ğŸ“– **README Principal:** [main branch](../../tree/main)

---

**Desenvolvido com ğŸ e â¤ï¸ - Demonstrando o poder do Apache Kafka!**
